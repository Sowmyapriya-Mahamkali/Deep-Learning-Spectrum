{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPF2eVImbZ3U",
        "outputId": "6da44e87-13e1-4aaa-e7ec-8626e8677272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 485kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.51MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM-ready data: torch.Size([60000, 28, 28]) torch.Size([60000])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# MNIST as 28x28 → sequence length = 28, input_size = 28\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_set = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
        "test_set = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Convert to sequences\n",
        "def prepare_sequences(dataset):\n",
        "    X, y = [], []\n",
        "    for img, label in dataset:\n",
        "        # img: 1x28x28 -> 28x28 sequence\n",
        "        X.append(img.squeeze(0).T)  # transpose to (seq_len, input_size)\n",
        "        y.append(label)\n",
        "    return torch.stack(X), torch.tensor(y)\n",
        "\n",
        "X_train, y_train = prepare_sequences(train_set)\n",
        "X_test, y_test = prepare_sequences(test_set)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=64, shuffle=False)\n",
        "\n",
        "print(\"LSTM-ready data:\", X_train.shape, y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l5XG1_xbuXD",
        "outputId": "8d5e1bf2-9814-48de-83da-89d14d90b4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MNIST_LSTM(nn.Module):\n",
        "    def __init__(self, input_size=28, hidden_size=128, num_layers=2, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: batch, seq_len, input_size\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]  # take last timestep\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = MNIST_LSTM().to(device)\n"
      ],
      "metadata": {
        "id": "5E_SMutQbuTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "yHgppj0jbuRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lstm(model, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "train_lstm(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhnASCH-buO2",
        "outputId": "4eff7205-2e70-4eda-8cea-f2e10857223f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.4879\n",
            "Epoch 2/3, Loss: 0.1293\n",
            "Epoch 3/3, Loss: 0.0897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_lstm(model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "    print(f\"LSTM Test Accuracy: {100*correct/total:.2f}%\")\n",
        "\n",
        "evaluate_lstm(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIzAlWZ3buMZ",
        "outputId": "f012121b-963d-4502-de5c-cf70d25a123d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Test Accuracy: 97.65%\n"
          ]
        }
      ]
    }
  ]
}